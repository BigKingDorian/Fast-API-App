import logging
import os
import json
import base64
import asyncio
import time
import uuid
import subprocess
import requests  # ‚úÖ Added for ElevenLabs API
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from fastapi.responses import Response
from fastapi.staticfiles import StaticFiles  # ‚úÖ Added for serving audio
from twilio.twiml.voice_response import VoiceResponse, Start, Stream
from deepgram import DeepgramClient, LiveOptions, LiveTranscriptionEvents
from openai import OpenAI
from dotenv import load_dotenv
load_dotenv("/root/Fast-API-App/.env")

# Detect which VM / container you‚Äôre on
INSTANCE = (
    os.getenv("FLY_ALLOC_ID")      # Fly.io VM ID (present in production)
    or os.getenv("HOSTNAME")       # Docker / Kubernetes fallback
    or os.uname().nodename         # last-resort fallback
)

print(f"üÜî This app instance ID is: {INSTANCE}")

# Configure the root logger
logging.basicConfig(
    level=logging.INFO,
    format=f"[{INSTANCE}] %(asctime)s %(levelname)s: %(message)s",
    datefmt="%H:%M:%S",
)

log = logging.getLogger("app").info     # quick alias ‚Üí use log(...)

DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")  # ‚úÖ Also needed
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID")

if not DEEPGRAM_API_KEY:
    raise RuntimeError("Missing DEEPGRAM_API_KEY in environment")
if not OPENAI_API_KEY:
    raise RuntimeError("Missing OPENAI_API_KEY in environment")
if not ELEVENLABS_API_KEY:
    raise RuntimeError("Missing ELEVENLABS_API_KEY in environment")

# ‚úÖ Create the OpenAI client after loading the env
client = OpenAI(api_key=OPENAI_API_KEY)

# Simple in-memory session store
session_memory = {}

# ‚úÖ Create FastAPI app and mount static audio folder
app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

def save_transcript(call_sid, user_transcript=None, audio_path=None, gpt_response=None):
    if call_sid not in session_memory:
        session_memory[call_sid] = {}
    if user_transcript:
        session_memory[call_sid]["user_transcript"] = user_transcript
    if gpt_response:
        session_memory[call_sid]["gpt_response"] = gpt_response
    if audio_path:
        session_memory[call_sid]["audio_path"] = audio_path
        
async def get_last_transcript_for_this_call(call_sid):
    for i in range(40):  # wait up to 4s
        data = session_memory.get(call_sid)
        transcript = data.get("user_transcript") if data else None
        if transcript and transcript.strip():
            return transcript
        await asyncio.sleep(0.1)
    return None

def get_last_audio_for_call(call_sid):
    data = session_memory.get(call_sid)

    if data and "audio_path" in data:
        log(f"üéß Retrieved audio path for {call_sid}: {data['audio_path']}")
        return data["audio_path"]
    else:
        logging.error(f"‚ùå No audio path found for {call_sid} in session memory.")
        return None

# ‚úÖ GPT handler function
async def get_gpt_response(user_text: str) -> str:
    try:
        if not user_text or not user_text.strip():
            raise ValueError("üõë GPT called with empty input")
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a helpful AI assistant named Lotus. Keep your responses clear and concise."},
                {"role": "user", "content": user_text}
            ]
        )
        return response.choices[0].message.content or "[GPT returned empty message]"
    except Exception as e:
        print(f"‚ö†Ô∏è GPT Error: {e}")
        return "[GPT failed to respond]"

# ‚úÖ Helper to run GPT in executor from a thread
async def print_gpt_response(sentence: str):
    response = await get_gpt_response(sentence)
    print(f"ü§ñ GPT: {response}")
    
    # Step 3: Save audio to file
    audio_bytes = audio_response.content
    
    # üëá Make unique filename with UUID
    unique_id = str(uuid.uuid4())
    filename = f"response_{unique_id}.wav"
    file_path = f"static/audio/{filename}"
    converted_path = f"static/audio/response_{unique_id}_ulaw.wav"

    print(f"üîä Audio file size: {len(audio_bytes)} bytes")
    print(f"üíæ Saving audio to {file_path}")
    
    os.makedirs("static/audio", exist_ok=True)
    with open(file_path, "wb") as f:  # ‚úÖ use dynamic path
        f.write(audio_bytes)
        print("‚úÖ Audio file saved at:", file_path)
        print(f"üéß Got {len(audio_bytes)} audio bytes from ElevenLabs")
        
    for _ in range(10):  # wait up to 5 seconds
        if os.path.exists(converted_path):
            print("‚úÖ File exists for playback:", converted_path)
            break
        print("‚åõ Waiting for file to become available...")
        time.sleep(0.5)
    else:
        print("‚ùå File still not found after 5 seconds!")
        
class VerboseStaticFiles(StaticFiles):
    async def get_response(self, path: str, scope):
        #Build full URL
        scheme   = scope.get("scheme", "http")
        host     = dict(scope["headers"]).get(b"host", b"-").decode()
        full_url = f"{scheme}://{host}{scope['path']}"

        abs_path = os.path.abspath(os.path.join(self.directory, path))
        exists   = os.path.exists(abs_path)
        readable = os.access(abs_path, os.R_OK)

        log(
            f"üìÇ Static GET {path!r} ‚Üí exists={exists} "
            f"readable={readable} size={os.path.getsize(abs_path) if exists else '‚Äî'}"
        )

        if not exists:
            try:
                parent = os.path.dirname(abs_path)
                log("üìë Dir listing: %s", os.listdir(parent))
            except Exception as e:
                log("‚ö†Ô∏è Could not list directory: %s", e)

        return await super().get_response(path, scope)
        
@app.post("/")
async def twilio_voice_webhook(request: Request):
    print("\nüìû ‚îÄ‚îÄ [POST] Twilio webhook hit ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    form_data = await request.form()
    call_sid = form_data.get("CallSid") or str(uuid.uuid4())
    print(f"üÜî Call SID: {call_sid}")
    print(f"üß† Current session_memory keys: {list(session_memory.keys())}")

    # üß† Pull or initialize session for this call
    session = session_memory.get(call_sid, {})
    
    # üö¶ Check if greeting has already been played
    if not session.get("greeting_played"):
        session["greeting_played"] = True
        session_memory[call_sid] = session  # ‚úÖ Important: persist the update
        vr = VoiceResponse()
        vr.redirect("/greeting")
        print("üëã First-time caller ‚Äî redirecting to greeting handler.")
        return Response(content=str(vr), media_type="application/xml")

    # ‚îÄ‚îÄ 2. PULL LAST TRANSCRIPT (if any) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    gpt_input = await get_last_transcript_for_this_call(call_sid)
    print(f"üìù GPT input candidate: \"{gpt_input}\"")

    if not gpt_input:
        print("‚ùå No valid transcript received. Skipping GPT call.")
        # Optionally say something like: "I didn't catch that, can you repeat?"
        gpt_text = "Sorry, I didn't catch that. Could you please repeat?"
    else:
        gpt_text = await get_gpt_response(gpt_input)
        session_memory[call_sid]["user_transcript"] = None  # ‚úÖ clear it

    # üßº Clear the transcript to avoid reuse in next round
    session_memory[call_sid]["user_transcript"] = None

    # ‚îÄ‚îÄ 3. TEXT-TO-SPEECH WITH ELEVENLABS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    elevenlabs_response = requests.post(
        f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}",
        headers={
            "xi-api-key": os.getenv("ELEVENLABS_API_KEY"),
            "Content-Type": "application/json"
        },
        json={
            "text": gpt_text,
            "model_id": "eleven_flash_v2_5",
            "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
        }
    )
    
    print("üß™ ElevenLabs status:", elevenlabs_response.status_code)
    print("üß™ ElevenLabs content type:", elevenlabs_response.headers.get("Content-Type")) 
    print("üõ∞Ô∏è ElevenLabs Status Code:", elevenlabs_response.status_code)
    print("üõ∞Ô∏è ElevenLabs Content-Type:", elevenlabs_response.headers.get("Content-Type"))
    print("üõ∞Ô∏è ElevenLabs Response Length:", len(elevenlabs_response.content), "bytes")
    print("üõ∞Ô∏è ElevenLabs Content (first 500 bytes):", elevenlabs_response.content[:500])
    print(f"üéôÔ∏è ElevenLabs status {elevenlabs_response.status_code}, "
          f"bytes {len(elevenlabs_response.content)}")

    audio_bytes = elevenlabs_response.content
    unique_id = uuid.uuid4().hex
    file_path = f"static/audio/response_{unique_id}.wav"

    with open(file_path, "wb") as f:
        f.write(audio_bytes)
    print(f"üíæ Saved original WAV ‚Üí {file_path}")

    await asyncio.sleep(1)

    # ‚úÖ Failure check with print statements
    if not audio_bytes or elevenlabs_response.status_code != 200:
        print("‚ùå ElevenLabs failed or returned empty audio!")
        print("üîÅ GPT Text:", gpt_text)
        print("üõë Status:", elevenlabs_response.status_code)
        print("üìú Response:", elevenlabs_response.text)
        return Response("Audio generation failed.", status_code=500)
        
    # ‚îÄ‚îÄ 4. CONVERT TO Œº-LAW 8 kHz ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    converted_path = f"static/audio/response_{unique_id}_ulaw.wav"
    try:
        subprocess.run([
            "/usr/bin/ffmpeg", "-y", "-i", file_path,
            "-ar", "8000", "-ac", "1", "-c:a", "pcm_mulaw", converted_path
        ], check=True)
    except subprocess.CalledProcessError as e:
        print(f"‚ùå FFmpeg failed: {e}")
        return Response("Audio conversion failed", status_code=500)
    print("üß≠ Checking absolute path:", os.path.abspath(converted_path))
    # ‚úÖ Wait for file to become available (race condition guard)
    for i in range(40):
        if os.path.isfile(converted_path):
            print(f"‚úÖ Found converted file after {i * 0.1:.1f}s")
            break
        await asyncio.sleep(0.1)
    else:
        print("‚ùå Converted file never appeared ‚Äî aborting")
        return Response("Converted audio not available", status_code=500)
    print(f"üéõÔ∏è Converted WAV (8 kHz Œº-law) ‚Üí {converted_path}")
    log("‚úÖ Audio file saved at %s", converted_path)
    # ‚úÖ Only save if audio is a reasonable size (avoid silent/broken audio)
    if len(audio_bytes) > 2000:
        save_transcript(call_sid, audio_path=converted_path, gpt_response=gpt_text)
        print(f"üß† Session updated AFTER save: {session_memory.get(call_sid)}")
    else:
        print("‚ö†Ô∏è Skipping transcript/audio save due to likely blank response.")

    # ‚îÄ‚îÄ 5. BUILD TWIML ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    vr = VoiceResponse()

    # Start Deepgram stream
    start = Start()
    start.stream(
        url="wss://silent-sound-1030.fly.dev/media",
        content_type="audio/x-mulaw;rate=8000"
    )
    vr.append(start)

    log("üì° Starting Deepgram stream to WebSocket endpoint")

    # Try to retrieve the most recent converted file with retries
    audio_path = None
    for _ in range(10):
        current_path = get_last_audio_for_call(call_sid)
        log(f"üîÅ Checking session memory for {call_sid} ‚Üí {current_path}")
        print(f"üîé Full session_memory[{call_sid}] = {json.dumps(session_memory.get(call_sid), indent=2)}")
        if current_path and os.path.exists(current_path):
            audio_path = current_path
            break
        await asyncio.sleep(1)

    if audio_path:
        ulaw_filename = os.path.basename(audio_path)
        vr.play(f"https://silent-sound-1030.fly.dev/static/audio/{ulaw_filename}")
        print("üîó Final playback URL:", f"https://silent-sound-1030.fly.dev/static/audio/{ulaw_filename}")
        print(f"‚úÖ Queued audio for playback: {ulaw_filename}")
    else:
        print("‚ùå Audio not found after retry loop")
        vr.say("Sorry, something went wrong.")
        
    # ‚úÖ Replace hangup with redirect back to self
    vr.redirect("/")
    print("üìù Returning TwiML to Twilio (with redirect).")
    return Response(content=str(vr), media_type="application/xml")

@app.post("/greeting")
async def greeting_rout(request: Request):
    print("\nüìû ‚îÄ‚îÄ [POST] Greeting handler hit ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    form_data = await request.form()
    call_sid = form_data.get("CallSid") or str(uuid.uuid4())
    print(f"üÜî Call SID: {call_sid}")
    print(f"üß† Current session_memory keys: {list(session_memory.keys())}")

    # ‚îÄ‚îÄ 2. 1 TIME GREETING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    gpt_text = "Hello my name is Lotus, how can I help you today?"        
    print(f"‚úÖ GPT greeting: \"{gpt_text}\"")

    # ‚îÄ‚îÄ 3. TEXT-TO-SPEECH WITH ELEVENLABS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    elevenlabs_response = requests.post(
        f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}",
        headers={
            "xi-api-key": os.getenv("ELEVENLABS_API_KEY"),
            "Content-Type": "application/json"
        },
        json={
            "text": gpt_text,
            "model_id": "eleven_flash_v2_5",
            "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
        }
    )
    
    print("üß™ ElevenLabs status:", elevenlabs_response.status_code)
    print("üß™ ElevenLabs content type:", elevenlabs_response.headers.get("Content-Type")) 
    print("üõ∞Ô∏è ElevenLabs Status Code:", elevenlabs_response.status_code)
    print("üõ∞Ô∏è ElevenLabs Content-Type:", elevenlabs_response.headers.get("Content-Type"))
    print("üõ∞Ô∏è ElevenLabs Response Length:", len(elevenlabs_response.content), "bytes")
    print("üõ∞Ô∏è ElevenLabs Content (first 500 bytes):", elevenlabs_response.content[:500])
    print(f"üéôÔ∏è ElevenLabs status {elevenlabs_response.status_code}, "
          f"bytes {len(elevenlabs_response.content)}")

    audio_bytes = elevenlabs_response.content
    unique_id = uuid.uuid4().hex
    file_path = f"static/audio/response_{unique_id}.wav"

    with open(file_path, "wb") as f:
        f.write(audio_bytes)
    print(f"üíæ Saved original WAV ‚Üí {file_path}")

    await asyncio.sleep(1)

    # ‚úÖ Failure check with print statements
    if not audio_bytes or elevenlabs_response.status_code != 200:
        print("‚ùå ElevenLabs failed or returned empty audio!")
        print("üîÅ GPT Text:", gpt_text)
        print("üõë Status:", elevenlabs_response.status_code)
        print("üìú Response:", elevenlabs_response.text)
        return Response("Audio generation failed.", status_code=500)
        
    # ‚îÄ‚îÄ 4. CONVERT TO Œº-LAW 8 kHz ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    converted_path = f"static/audio/response_{unique_id}_ulaw.wav"
    try:
        subprocess.run([
            "/usr/bin/ffmpeg", "-y", "-i", file_path,
            "-ar", "8000", "-ac", "1", "-c:a", "pcm_mulaw", converted_path
        ], check=True)
    except subprocess.CalledProcessError as e:
        print(f"‚ùå FFmpeg failed: {e}")
        return Response("Audio conversion failed", status_code=500)
    print("üß≠ Checking absolute path:", os.path.abspath(converted_path))
    # ‚úÖ Wait for file to become available (race condition guard)
    for i in range(40):
        if os.path.isfile(converted_path):
            print(f"‚úÖ Found converted file after {i * 0.1:.1f}s")
            break
        await asyncio.sleep(0.1)
    else:
        print("‚ùå Converted file never appeared ‚Äî aborting")
        return Response("Converted audio not available", status_code=500)
    print(f"üéõÔ∏è Converted WAV (8 kHz Œº-law) ‚Üí {converted_path}")
    log("‚úÖ Audio file saved at %s", converted_path)
    # ‚úÖ Only save if audio is a reasonable size (avoid silent/broken audio)
    if len(audio_bytes) > 2000:
        save_transcript(call_sid, audio_path=converted_path, gpt_response=gpt_text)
        print(f"üß† Session updated AFTER save: {session_memory.get(call_sid)}")
    else:
        print("‚ö†Ô∏è Skipping transcript/audio save due to likely blank response.")

    # ‚îÄ‚îÄ 5. BUILD TWIML ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    vr = VoiceResponse()

    # Start Deepgram stream
    start = Start()
    start.stream(
        url="wss://silent-sound-1030.fly.dev/media",
        content_type="audio/x-mulaw;rate=8000"
    )
    vr.append(start)

    log("üì° Starting Deepgram stream to WebSocket endpoint")

    # Try to retrieve the most recent converted file with retries
    audio_path = None
    for _ in range(10):
        current_path = get_last_audio_for_call(call_sid)
        log(f"üîÅ Checking session memory for {call_sid} ‚Üí {current_path}")
        print(f"üîé Full session_memory[{call_sid}] = {json.dumps(session_memory.get(call_sid), indent=2)}")
        if current_path and os.path.exists(current_path):
            audio_path = current_path
            break
        await asyncio.sleep(1)

    if audio_path:
        ulaw_filename = os.path.basename(audio_path)
        vr.play(f"https://silent-sound-1030.fly.dev/static/audio/{ulaw_filename}")
        print("üîó Final playback URL:", f"https://silent-sound-1030.fly.dev/static/audio/{ulaw_filename}")
        print(f"‚úÖ Queued audio for playback: {ulaw_filename}")
    else:
        print("‚ùå Audio not found after retry loop")
        vr.say("Sorry, something went wrong.")
        
    # ‚úÖ Replace hangup with redirect back to self
    vr.redirect("/")
    print("üìù Returning TwiML to Twilio (with redirect).")
    return Response(content=str(vr), media_type="application/xml")

@app.websocket("/media")
async def media_stream(ws: WebSocket):
    await ws.accept()
    print("‚òÖ Twilio WebSocket connected")

    call_sid_holder = {"sid": None}
    last_input_time = {"ts": time.time()}
    last_transcript = {"text": "", "confidence": 0.5, "is_final": False}
    finished = {"done": False}
    
    loop = asyncio.get_running_loop()
    deepgram = DeepgramClient(DEEPGRAM_API_KEY)
    dg_connection = None
    
    try:
        print("‚öôÔ∏è Connecting to Deepgram live transcription...")

        try:
            live_client = deepgram.listen.live

            deepgram_options = {
                "punctuate": True,
                "interim_results": True,
                "endpointing": 800  # üü¢ Wait 800ms of silence before finalizing
                }
            
            dg_connection = await asyncio.to_thread(live_client.v, "1")
        except Exception as e:
            print(f"‚õî Failed to create Deepgram connection: {e}")
            await ws.close()
            return

        def on_transcript(*args, **kwargs):
            try:
                print("üì• RAW transcript event:")
                result = kwargs.get("result") or (args[0] if args else None)
                metadata = kwargs.get("metadata")

                if result is None:
                    print("‚ö†Ô∏è No result received.")
                    return

                print("üìÇ Type of result:", type(result))

                if hasattr(result, "to_dict"):
                    payload = result.to_dict()
                    print(json.dumps(payload, indent=2))

                    try:
                        alt = payload["channel"]["alternatives"][0]
                        sentence = alt.get("transcript", "")
                        confidence = alt.get("confidence", 0.0)
                        is_final = payload["is_final"] if "is_final" in payload else False
                        
                        if sentence:
                            print(f"üìù {sentence} (confidence: {confidence})")
                            last_input_time["ts"] = time.time()
                            last_transcript["text"] = sentence
                            last_transcript["confidence"] = confidence
                            last_transcript["is_final"] = payload.get("is_final", False)
                            
                            if call_sid_holder["sid"]:
                                sid = call_sid_holder["sid"]
                                save_transcript(sid, user_transcript=sentence)
                                session_memory.setdefault(sid, {})            # ensure dict exists
                                session_memory[sid]["ready"] = True

                                print(f"‚úÖ [WS] Marked call {call_sid_holder['sid']} as ready")

                    except KeyError as e:
                        print(f"‚ö†Ô∏è Missing expected key in payload: {e}")
                    except Exception as inner_e:
                        print(f"‚ö†Ô∏è Could not extract transcript sentence: {inner_e}")
            except Exception as e:  # ‚Üê This closes the OUTER try
                print(f"‚ö†Ô∏è Error handling transcript: {e}")
                
        dg_connection.on(LiveTranscriptionEvents.Transcript, on_transcript)

        options = LiveOptions(
            model="nova-3",
            language="en-US",
            encoding="mulaw",
            sample_rate=8000,
            punctuate=True,
        )
        print("‚úèÔ∏è LiveOptions being sent:", options.__dict__)
        dg_connection.start(options)
        print("‚úÖ Deepgram connection started")
        
        async def monitor_user_done():
            while not finished["done"]:
                await asyncio.sleep(0.5)
                elapsed = time.time() - last_input_time["ts"]
        
                if (
                    elapsed > 2.0 and
                    last_transcript["confidence"] >= 0.5 and
                    last_transcript.get("is_final", False)
                ):
                    print(f"‚úÖ User finished speaking (elapsed: {elapsed:.1f}s, confidence: {last_transcript['confidence']})")
                    finished["done"] = True
                    
                    print("‚è≥ Waiting for POST to handle GPT + TTS...")
                    for _ in range(40):  # up to 4 seconds
                        audio_path = session_memory.get(call_sid_holder["sid"], {}).get("audio_path")
                        if audio_path and os.path.exists(audio_path):
                            print(f"‚úÖ POST-generated audio is ready: {audio_path}")
                            break
                        await asyncio.sleep(0.1)
                    else:
                        print("‚ùå Timed out waiting for POST to generate GPT audio.")
                        
        loop.create_task(monitor_user_done())
        
        async def sender():
            while True:
                try:
                    raw = await ws.receive_text()
                except WebSocketDisconnect:
                    print("‚úñÔ∏è Twilio WebSocket disconnected")
                    break
                except Exception as e:
                    print(f"‚ö†Ô∏è Unexpected error receiving message: {e}")
                    break

                try:
                    msg = json.loads(raw)
                    print("üì© Incoming message:", msg.get("event"))
                except json.JSONDecodeError as e:
                    print(f"‚ö†Ô∏è JSON decode error: {e}")
                    continue

                event = msg.get("event")

                if event == "start":
                    print("‚ñ∂Ô∏è Stream started (StreamSid:", msg["start"].get("streamSid"), ")")

                    # Debug print to inspect what Twilio actually sent
                    print("üßæ Twilio start event data:", json.dumps(msg["start"], indent=2))

                    # Try all possible keys Twilio might send
                    sid = (
                        msg["start"].get("callSid") or
                        msg["start"].get("CallSid") or
                        msg["start"].get("callerSid") or
                        msg["start"].get("CallerSid")
                    )

                    call_sid_holder["sid"] = sid
                    print(f"üìû [WebSocket] call_sid_holder['sid']: {call_sid_holder['sid']}")
                    
                elif event == "media":
                    print("üì° Media event received")
                    try:
                        payload = base64.b64decode(msg["media"]["payload"])
                        dg_connection.send(payload)
                        last_input_time["ts"] = time.time()
                        print(f"üì¶ Sent {len(payload)} bytes to Deepgram (event: media)")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error sending to Deepgram: {e}")

                elif event == "stop":
                    print("‚èπ Stream stopped by Twilio")
                    break

        await sender()

    except Exception as e:
        print(f"‚õî Deepgram error: {e}")

    finally:
        if dg_connection:
            try:
                dg_connection.finish()
            except Exception as e:
                print(f"‚ö†Ô∏è Error closing Deepgram connection: {e}")
        try:
            await ws.close()
        except Exception as e:
            print(f"‚ö†Ô∏è Error closing WebSocket: {e}")
        print("‚úÖ Connection closed")
        
