import os
import json
import base64
import asyncio
import time
import uuid
import subprocess
import requestsÂ  # âœ… ElevenLabs API
import logging
from logging.handlers import RotatingFileHandler
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Request
from fastapi.responses import Response
from fastapi.staticfiles import StaticFilesÂ  # âœ… Serving audio
from twilio.twiml.voice_response import VoiceResponse, Start, Stream
from deepgram import DeepgramClient, LiveOptions, LiveTranscriptionEvents
from openai import OpenAI
from dotenv import load_dotenv

# ğŸ”„ Load .env file
load_dotenv("/root/Fast-API-App/.env")

# ğŸ—‚ï¸ Log file config
LOG_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "logs")
LOG_FILE = f"{LOG_DIR}/app.log"
os.makedirs(LOG_DIR, exist_ok=True)

# ğŸ› ï¸ Touch the log file to verify path
with open(LOG_FILE, "a") as f:
Â Â Â Â f.write("ğŸŸ¢ Log file was touched.\n")

# ğŸ”§ Setup Rotating File Handler
file_handler = RotatingFileHandler(LOG_FILE, maxBytes=10_000_000, backupCount=3)
file_handler.setLevel(logging.DEBUG)
file_handler.setFormatter(logging.Formatter(
Â Â Â Â "[%(asctime)s] [%(levelname)s] %(message)s", "%Y-%m-%d %H:%M:%S"
))

# ğŸ–¥ï¸ Optional: Stream to terminal
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(logging.Formatter(
Â Â Â Â "[%(asctime)s] [%(levelname)s] %(message)s", "%Y-%m-%d %H:%M:%S"
))

# ğŸš¨ IMPORTANT: Don't call logging.basicConfig after handlers are added
# It won't do anything once handlers are set â€” skip it!
# logging.basicConfig(...) â† REMOVE THIS

# ğŸ”— Apply handlers
logger = logging.getLogger()
logger.setLevel(logging.DEBUG)
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# ğŸ” Quick alias for log
log = logger.info

# âœ… Prove itâ€™s working
logger.info("âœ… Log setup complete.")

# ğŸ†” Instance identifier (for distributed logging)
INSTANCE = (
Â Â Â Â os.getenv("FLY_ALLOC_ID")Â  Â  Â  # Fly.io VM ID
Â Â Â Â or os.getenv("HOSTNAME") Â  Â  Â  # Docker/k8s fallback
Â Â Â Â or os.uname().nodename Â  Â  Â  Â  # Final fallback
)
logger.info(f"ğŸ†” App instance ID: {INSTANCE}")

# ğŸ” Load API keys
DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
ELEVENLABS_VOICE_ID = os.getenv("ELEVENLABS_VOICE_ID")

# ğŸš« Fail fast if missing secrets
if not DEEPGRAM_API_KEY:
Â Â Â Â raise RuntimeError("Missing DEEPGRAM_API_KEY in environment")
if not OPENAI_API_KEY:
Â Â Â Â raise RuntimeError("Missing OPENAI_API_KEY in environment")
if not ELEVENLABS_API_KEY:
Â Â Â Â raise RuntimeError("Missing ELEVENLABS_API_KEY in environment")

# ğŸ§  OpenAI client
client = OpenAI(api_key=OPENAI_API_KEY)

# ğŸ§  In-memory session
session_memory = {}

# âš™ï¸ FastAPI app
app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")

def save_transcript(call_sid, user_transcript=None, audio_path=None, gpt_response=None):
Â Â Â Â if call_sid not in session_memory:
Â Â Â Â Â Â Â Â session_memory[call_sid] = {}

Â Â Â Â if user_transcript:
Â Â Â Â Â Â Â Â session_memory[call_sid]["user_transcript"] = user_transcript
Â Â Â Â Â Â Â Â session_memory[call_sid]["transcript_version"] = time.time()Â  # ğŸ‘ˆ Add this line

Â Â Â Â if gpt_response:
Â Â Â Â Â Â Â Â session_memory[call_sid]["gpt_response"] = gpt_response
Â Â Â Â if audio_path:
Â Â Â Â Â Â Â Â session_memory[call_sid]["audio_path"] = audio_path
Â Â Â Â Â Â Â Â 
async def get_last_transcript_for_this_call(call_sid, last_known_version=None):
Â Â Â Â while True:
Â Â Â Â Â Â Â Â data = session_memory.get(call_sid)
Â Â Â Â Â Â Â Â if data and data.get("user_transcript"):
Â Â Â Â Â Â Â Â Â Â Â Â version = data.get("transcript_version", 0)
Â Â Â Â Â Â Â Â Â Â Â Â if last_known_version is None or version > last_known_version:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â return data["user_transcript"], version
Â Â Â Â Â Â Â Â await asyncio.sleep(0.1)

def get_last_audio_for_call(call_sid):
Â Â Â Â data = session_memory.get(call_sid)

Â Â Â Â if data and "audio_path" in data:
Â Â Â Â Â Â Â Â log(f"ğŸ§ Retrieved audio path for {call_sid}: {data['audio_path']}")
Â Â Â Â Â Â Â Â return data["audio_path"]
Â Â Â Â else:
Â Â Â Â Â Â Â Â logging.error(f"âŒ No audio path found for {call_sid} in session memory.")
Â Â Â Â Â Â Â Â return None

# âœ… GPT handler function
async def get_gpt_response(user_text: str) -> str:
Â Â Â Â try:
Â Â Â Â Â Â Â Â safe_text = "" if user_text is None else str(user_text)
Â Â Â Â Â Â Â Â if not safe_text.strip():
Â Â Â Â Â Â Â Â Â Â Â Â safe_text = "Hello, how can I help you today?"
Â Â Â Â Â Â Â Â response = client.chat.completions.create(
Â Â Â Â Â Â Â Â Â Â Â Â model="gpt-4o",
Â Â Â Â Â Â Â Â Â Â Â Â messages=[
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â {"role": "system", "content": "You are a helpful AI assistant named Lotus. Keep your responses clear and concise."},
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â {"role": "user", "content": safe_text}
Â Â Â Â Â Â Â Â Â Â Â Â ]
Â Â Â Â Â Â Â Â )
Â Â Â Â Â Â Â Â return response.choices[0].message.content or "[GPT returned empty message]"
Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â print(f"âš ï¸ GPT Error: {e}")
Â Â Â Â Â Â Â Â return "[GPT failed to respond]"

# âœ… Helper to run GPT in executor from a thread
async def print_gpt_response(sentence: str):
Â Â Â Â response = await get_gpt_response(sentence)
Â Â Â Â print(f"ğŸ¤– GPT: {response}")
Â Â Â Â 
Â Â Â Â # Step 3: Save audio to file
Â Â Â Â audio_bytes = audio_response.content
Â Â Â Â 
Â Â Â Â # ğŸ‘‡ Make unique filename with UUID
Â Â Â Â unique_id = str(uuid.uuid4())
Â Â Â Â filename = f"response_{unique_id}.wav"
Â Â Â Â file_path = f"static/audio/{filename}"
Â Â Â Â converted_path = f"static/audio/response_{unique_id}_ulaw.wav"

Â Â Â Â print(f"ğŸ”Š Audio file size: {len(audio_bytes)} bytes")
Â Â Â Â print(f"ğŸ’¾ Saving audio to {file_path}")
Â Â Â Â 
Â Â Â Â os.makedirs("static/audio", exist_ok=True)
Â Â Â Â with open(file_path, "wb") as f:Â  # âœ… use dynamic path
Â Â Â Â Â Â Â Â f.write(audio_bytes)
Â Â Â Â Â Â Â Â print("âœ… Audio file saved at:", file_path)
Â Â Â Â Â Â Â Â print(f"ğŸ§ Got {len(audio_bytes)} audio bytes from ElevenLabs")
Â Â Â Â Â Â Â Â 
Â Â Â Â for _ in range(10):Â  # wait up to 5 seconds
Â Â Â Â Â Â Â Â if os.path.exists(converted_path):
Â Â Â Â Â Â Â Â Â Â Â Â print("âœ… File exists for playback:", converted_path)
Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â Â Â Â Â print("âŒ› Waiting for file to become available...")
Â Â Â Â Â Â Â Â time.sleep(0.5)
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("âŒ File still not found after 5 seconds!")
Â Â Â Â Â Â Â Â 
class VerboseStaticFiles(StaticFiles):
Â Â Â Â async def get_response(self, path: str, scope):
Â Â Â Â Â Â Â Â #Build full URL
Â Â Â Â Â Â Â Â scheme Â  = scope.get("scheme", "http")
Â Â Â Â Â Â Â Â host Â  Â  = dict(scope["headers"]).get(b"host", b"-").decode()
Â Â Â Â Â Â Â Â full_url = f"{scheme}://{host}{scope['path']}"

Â Â Â Â Â Â Â Â abs_path = os.path.abspath(os.path.join(self.directory, path))
Â Â Â Â Â Â Â Â exists Â  = os.path.exists(abs_path)
Â Â Â Â Â Â Â Â readable = os.access(abs_path, os.R_OK)

Â Â Â Â Â Â Â Â log(
Â Â Â Â Â Â Â Â Â Â Â Â f"ğŸ“‚ Static GET {path!r} â†’ exists={exists} "
Â Â Â Â Â Â Â Â Â Â Â Â f"readable={readable} size={os.path.getsize(abs_path) if exists else 'â€”'}"
Â Â Â Â Â Â Â Â )

Â Â Â Â Â Â Â Â if not exists:
Â Â Â Â Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â parent = os.path.dirname(abs_path)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â log("ğŸ“‘ Dir listing: %s", os.listdir(parent))
Â Â Â Â Â Â Â Â Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â log("âš ï¸ Could not list directory: %s", e)

Â Â Â Â Â Â Â Â return await super().get_response(path, scope)
Â Â Â Â Â Â Â Â 
@app.post("/")
async def twilio_voice_webhook(request: Request):
Â Â Â Â print("\nğŸ“ â”€â”€ [POST] Twilio webhook hit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
Â Â Â Â form_data = await request.form()
Â Â Â Â call_sid = form_data.get("CallSid") or str(uuid.uuid4())
Â Â Â Â print(f"ğŸ†” Call SID: {call_sid}")
Â Â Â Â print(f"ğŸ§  Current session_memory keys: {list(session_memory.keys())}")

Â Â Â Â # ğŸ§  Pull or initialize session for this call
Â Â Â Â session = session_memory.get(call_sid, {})
Â Â Â Â 
Â Â Â Â # ğŸš¦ Check if greeting has already been played
Â Â Â Â if not session.get("greeting_played"):
Â Â Â Â Â Â Â Â session["greeting_played"] = True
Â Â Â Â Â Â Â Â session_memory[call_sid] = sessionÂ  # âœ… Important: persist the update
Â Â Â Â Â Â Â Â vr = VoiceResponse()
Â Â Â Â Â Â Â Â vr.redirect("/greeting")
Â Â Â Â Â Â Â Â print("ğŸ‘‹ First-time caller â€” redirecting to greeting handler.")
Â Â Â Â Â Â Â Â return Response(content=str(vr), media_type="application/xml")

Â Â Â Â # â”€â”€ 2. PULL LAST TRANSCRIPT (if any) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â Â Â Â # Before waiting for new transcript
Â Â Â Â last_known_version = session_memory.get(call_sid, {}).get("transcript_version", 0)
Â Â Â Â # Wait for a newer one
Â Â Â Â gpt_input, new_version = await get_last_transcript_for_this_call(call_sid, last_known_version)
Â Â Â Â print(f"ğŸ“ GPT input candidate: \"{gpt_input}\"")
Â Â Â Â session_memory[call_sid]["debug_gpt_input_logged_at"] = time.time()

Â Â Â Â # Simple transcript quality check
Â Â Â Â if not gpt_input or len(gpt_input.strip()) < 4:
Â Â Â Â Â Â Â Â print("âš ï¸ Transcript too short or missing â€” asking user to repeat")
Â Â Â Â Â Â Â Â gpt_text = "Sorry, I didn't catch that. Could you please repeat yourself?"
Â Â Â Â else:
Â Â Â Â Â Â Â Â gpt_text = await get_gpt_response(gpt_input)

Â Â Â Â # ğŸ§¼ Clear the transcript to avoid reuse in next round
Â Â Â Â session_memory[call_sid]["user_transcript"] = None
Â Â Â Â session_memory[call_sid]["transcript_version"] = 0

Â Â Â Â # â”€â”€ 3. TEXT-TO-SPEECH WITH ELEVENLABS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â Â Â Â elevenlabs_response = requests.post(
Â Â Â Â Â Â Â Â f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}",
Â Â Â Â Â Â Â Â headers={
Â Â Â Â Â Â Â Â Â Â Â Â "xi-api-key": os.getenv("ELEVENLABS_API_KEY"),
Â Â Â Â Â Â Â Â Â Â Â Â "Content-Type": "application/json"
Â Â Â Â Â Â Â Â },
Â Â Â Â Â Â Â Â json={
Â Â Â Â Â Â Â Â Â Â Â Â "text": gpt_text,
Â Â Â Â Â Â Â Â Â Â Â Â "model_id": "eleven_flash_v2_5",
Â Â Â Â Â Â Â Â Â Â Â Â "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
Â Â Â Â Â Â Â Â }
Â Â Â Â )
Â Â Â Â 
Â Â Â Â print("ğŸ§ª ElevenLabs status:", elevenlabs_response.status_code)
Â Â Â Â print("ğŸ§ª ElevenLabs content type:", elevenlabs_response.headers.get("Content-Type"))Â 
Â Â Â Â print("ğŸ›°ï¸ ElevenLabs Status Code:", elevenlabs_response.status_code)
Â Â Â Â print("ğŸ›°ï¸ ElevenLabs Content-Type:", elevenlabs_response.headers.get("Content-Type"))
Â Â Â Â print("ğŸ›°ï¸ ElevenLabs Response Length:", len(elevenlabs_response.content), "bytes")
Â Â Â Â print("ğŸ›°ï¸ ElevenLabs Content (first 500 bytes):", elevenlabs_response.content[:500])
Â Â Â Â print(f"ğŸ™ï¸ ElevenLabs status {elevenlabs_response.status_code}, "
Â Â Â Â Â Â Â Â Â Â f"bytes {len(elevenlabs_response.content)}")

Â Â Â Â audio_bytes = elevenlabs_response.content
Â Â Â Â unique_id = uuid.uuid4().hex
Â Â Â Â file_path = f"static/audio/response_{unique_id}.wav"

Â Â Â Â with open(file_path, "wb") as f:
Â Â Â Â Â Â Â Â f.write(audio_bytes)
Â Â Â Â print(f"ğŸ’¾ Saved original WAV â†’ {file_path}")

Â Â Â Â await asyncio.sleep(1)

Â Â Â Â # âœ… Failure check with print statements
Â Â Â Â if not audio_bytes or elevenlabs_response.status_code != 200:
Â Â Â Â Â Â Â Â print("âŒ ElevenLabs failed or returned empty audio!")
Â Â Â Â Â Â Â Â print("ğŸ” GPT Text:", gpt_text)
Â Â Â Â Â Â Â Â print("ğŸ›‘ Status:", elevenlabs_response.status_code)
Â Â Â Â Â Â Â Â print("ğŸ“œ Response:", elevenlabs_response.text)
Â Â Â Â Â Â Â Â return Response("Audio generation failed.", status_code=500)
Â Â Â Â Â Â Â Â 
Â Â Â Â # â”€â”€ 4. CONVERT TO Î¼-LAW 8 kHz â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â Â Â Â converted_path = f"static/audio/response_{unique_id}_ulaw.wav"
Â Â Â Â try:
Â Â Â Â Â Â Â Â subprocess.run([
Â Â Â Â Â Â Â Â Â Â Â Â "/usr/bin/ffmpeg", "-y", "-i", file_path,
Â Â Â Â Â Â Â Â Â Â Â Â "-ar", "8000", "-ac", "1", "-c:a", "pcm_mulaw", converted_path
Â Â Â Â Â Â Â Â ], check=True)
Â Â Â Â except subprocess.CalledProcessError as e:
Â Â Â Â Â Â Â Â print(f"âŒ FFmpeg failed: {e}")
Â Â Â Â Â Â Â Â return Response("Audio conversion failed", status_code=500)
Â Â Â Â print("ğŸ§­ Checking absolute path:", os.path.abspath(converted_path))
Â Â Â Â # âœ… Wait for file to become available (race condition guard)
Â Â Â Â for i in range(40):
Â Â Â Â Â Â Â Â if os.path.isfile(converted_path):
Â Â Â Â Â Â Â Â Â Â Â Â print(f"âœ… Found converted file after {i * 0.1:.1f}s")
Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â Â Â Â Â await asyncio.sleep(0.1)
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("âŒ Converted file never appeared â€” aborting")
Â Â Â Â Â Â Â Â return Response("Converted audio not available", status_code=500)
Â Â Â Â print(f"ğŸ›ï¸ Converted WAV (8 kHz Î¼-law) â†’ {converted_path}")
Â Â Â Â log("âœ… Audio file saved at %s", converted_path)
Â Â Â Â # âœ… Only save if audio is a reasonable size (avoid silent/broken audio)
Â Â Â Â if len(audio_bytes) > 2000:
Â Â Â Â Â Â Â Â save_transcript(call_sid, audio_path=converted_path, gpt_response=gpt_text)
Â Â Â Â Â Â Â Â print(f"ğŸ§  Session updated AFTER save: {session_memory.get(call_sid)}")
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("âš ï¸ Skipping transcript/audio save due to likely blank response.")

Â Â Â Â # â”€â”€ 5. BUILD TWIML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â Â Â Â vr = VoiceResponse()

Â Â Â Â # Start Deepgram stream
Â Â Â Â start = Start()
Â Â Â Â start.stream(
Â Â Â Â Â Â Â Â url="wss://silent-sound-1030.fly.dev/media",
Â Â Â Â Â Â Â Â content_type="audio/x-mulaw;rate=8000"
Â Â Â Â )
Â Â Â Â vr.append(start)

Â Â Â Â log("ğŸ“¡ Starting Deepgram stream to WebSocket endpoint")

Â Â Â Â # Try to retrieve the most recent converted file with retries
Â Â Â Â audio_path = None
Â Â Â Â for _ in range(10):
Â Â Â Â Â Â Â Â current_path = get_last_audio_for_call(call_sid)
Â Â Â Â Â Â Â Â log(f"ğŸ” Checking session memory for {call_sid} â†’ {current_path}")
Â Â Â Â Â Â Â Â print(f"ğŸ” Full session_memory[{call_sid}] = {json.dumps(session_memory.get(call_sid), indent=2)}")
Â Â Â Â Â Â Â Â if current_path and os.path.exists(current_path):
Â Â Â Â Â Â Â Â Â Â Â Â audio_path = current_path
Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â Â Â Â Â await asyncio.sleep(1)

Â Â Â Â if audio_path:
Â Â Â Â Â Â Â Â ulaw_filename = os.path.basename(audio_path)
Â Â Â Â Â Â Â Â vr.play(f"https://silent-sound-1030.fly.dev/static/audio/{ulaw_filename}")
Â Â Â Â Â Â Â Â print("ğŸ”— Final playback URL:", f"https://silent-sound-1030.fly.dev/static/audio/{ulaw_filename}")
Â Â Â Â Â Â Â Â print(f"âœ… Queued audio for playback: {ulaw_filename}")
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("âŒ Audio not found after retry loop")
Â Â Â Â Â Â Â Â vr.say("Sorry, something went wrong.")
Â Â Â Â Â Â Â Â 
Â Â Â Â # âœ… Replace hangup with redirect back to self
Â Â Â Â vr.redirect("/")
Â Â Â Â print("ğŸ“ Returning TwiML to Twilio (with redirect).")
Â Â Â Â return Response(content=str(vr), media_type="application/xml")

@app.post("/greeting")
async def greeting_rout(request: Request):
Â Â Â Â print("\nğŸ“ â”€â”€ [POST] Greeting handler hit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
Â Â Â Â form_data = await request.form()
Â Â Â Â call_sid = form_data.get("CallSid") or str(uuid.uuid4())
Â Â Â Â print(f"ğŸ†” Call SID: {call_sid}")
Â Â Â Â print(f"ğŸ§  Current session_memory keys: {list(session_memory.keys())}")

Â Â Â Â # â”€â”€ 2. 1 TIME GREETING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â Â Â Â gpt_text = "Hello my name is Lotus, how can I help you today?"Â Â Â Â Â Â Â Â 
Â Â Â Â print(f"âœ… GPT greeting: \"{gpt_text}\"")

Â Â Â Â # â”€â”€ 3. TEXT-TO-SPEECH WITH ELEVENLABS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â Â Â Â elevenlabs_response = requests.post(
Â Â Â Â Â Â Â Â f"https://api.elevenlabs.io/v1/text-to-speech/{ELEVENLABS_VOICE_ID}",
Â Â Â Â Â Â Â Â headers={
Â Â Â Â Â Â Â Â Â Â Â Â "xi-api-key": os.getenv("ELEVENLABS_API_KEY"),
Â Â Â Â Â Â Â Â Â Â Â Â "Content-Type": "application/json"
Â Â Â Â Â Â Â Â },
Â Â Â Â Â Â Â Â json={
Â Â Â Â Â Â Â Â Â Â Â Â "text": gpt_text,
Â Â Â Â Â Â Â Â Â Â Â Â "model_id": "eleven_flash_v2_5",
Â Â Â Â Â Â Â Â Â Â Â Â "voice_settings": {"stability": 0.5, "similarity_boost": 0.75}
Â Â Â Â Â Â Â Â }
Â Â Â Â )
Â Â Â Â 
Â Â Â Â print("ğŸ§ª ElevenLabs status:", elevenlabs_response.status_code)
Â Â Â Â print("ğŸ§ª ElevenLabs content type:", elevenlabs_response.headers.get("Content-Type"))Â 
Â Â Â Â print("ğŸ›°ï¸ ElevenLabs Status Code:", elevenlabs_response.status_code)
Â Â Â Â print("ğŸ›°ï¸ ElevenLabs Content-Type:", elevenlabs_response.headers.get("Content-Type"))
Â Â Â Â print("ğŸ›°ï¸ ElevenLabs Response Length:", len(elevenlabs_response.content), "bytes")
Â Â Â Â print("ğŸ›°ï¸ ElevenLabs Content (first 500 bytes):", elevenlabs_response.content[:500])
Â Â Â Â print(f"ğŸ™ï¸ ElevenLabs status {elevenlabs_response.status_code}, "
Â Â Â Â Â Â Â Â Â Â f"bytes {len(elevenlabs_response.content)}")

Â Â Â Â audio_bytes = elevenlabs_response.content
Â Â Â Â unique_id = uuid.uuid4().hex
Â Â Â Â file_path = f"static/audio/response_{unique_id}.wav"

Â Â Â Â with open(file_path, "wb") as f:
Â Â Â Â Â Â Â Â f.write(audio_bytes)
Â Â Â Â print(f"ğŸ’¾ Saved original WAV â†’ {file_path}")

Â Â Â Â await asyncio.sleep(1)

Â Â Â Â # âœ… Failure check with print statements
Â Â Â Â if not audio_bytes or elevenlabs_response.status_code != 200:
Â Â Â Â Â Â Â Â print("âŒ ElevenLabs failed or returned empty audio!")
Â Â Â Â Â Â Â Â print("ğŸ” GPT Text:", gpt_text)
Â Â Â Â Â Â Â Â print("ğŸ›‘ Status:", elevenlabs_response.status_code)
Â Â Â Â Â Â Â Â print("ğŸ“œ Response:", elevenlabs_response.text)
Â Â Â Â Â Â Â Â return Response("Audio generation failed.", status_code=500)
Â Â Â Â Â Â Â Â 
Â Â Â Â # â”€â”€ 4. CONVERT TO Î¼-LAW 8 kHz â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â Â Â Â converted_path = f"static/audio/response_{unique_id}_ulaw.wav"
Â Â Â Â try:
Â Â Â Â Â Â Â Â subprocess.run([
Â Â Â Â Â Â Â Â Â Â Â Â "/usr/bin/ffmpeg", "-y", "-i", file_path,
Â Â Â Â Â Â Â Â Â Â Â Â "-ar", "8000", "-ac", "1", "-c:a", "pcm_mulaw", converted_path
Â Â Â Â Â Â Â Â ], check=True)
Â Â Â Â except subprocess.CalledProcessError as e:
Â Â Â Â Â Â Â Â print(f"âŒ FFmpeg failed: {e}")
Â Â Â Â Â Â Â Â return Response("Audio conversion failed", status_code=500)
Â Â Â Â print("ğŸ§­ Checking absolute path:", os.path.abspath(converted_path))
Â Â Â Â # âœ… Wait for file to become available (race condition guard)
Â Â Â Â for i in range(40):
Â Â Â Â Â Â Â Â if os.path.isfile(converted_path):
Â Â Â Â Â Â Â Â Â Â Â Â print(f"âœ… Found converted file after {i * 0.1:.1f}s")
Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â Â Â Â Â await asyncio.sleep(0.1)
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("âŒ Converted file never appeared â€” aborting")
Â Â Â Â Â Â Â Â return Response("Converted audio not available", status_code=500)
Â Â Â Â print(f"ğŸ›ï¸ Converted WAV (8 kHz Î¼-law) â†’ {converted_path}")
Â Â Â Â log("âœ… Audio file saved at %s", converted_path)
Â Â Â Â # âœ… Only save if audio is a reasonable size (avoid silent/broken audio)
Â Â Â Â if len(audio_bytes) > 2000:
Â Â Â Â Â Â Â Â save_transcript(call_sid, audio_path=converted_path, gpt_response=gpt_text)
Â Â Â Â Â Â Â Â print(f"ğŸ§  Session updated AFTER save: {session_memory.get(call_sid)}")
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("âš ï¸ Skipping transcript/audio save due to likely blank response.")

Â Â Â Â # â”€â”€ 5. BUILD TWIML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Â Â Â Â vr = VoiceResponse()

Â Â Â Â # Start Deepgram stream
Â Â Â Â start = Start()
Â Â Â Â start.stream(
Â Â Â Â Â Â Â Â url="wss://silent-sound-1030.fly.dev/media",
Â Â Â Â Â Â Â Â content_type="audio/x-mulaw;rate=8000"
Â Â Â Â )
Â Â Â Â vr.append(start)

Â Â Â Â log("ğŸ“¡ Starting Deepgram stream to WebSocket endpoint")

Â Â Â Â # Try to retrieve the most recent converted file with retries
Â Â Â Â audio_path = None
Â Â Â Â for _ in range(10):
Â Â Â Â Â Â Â Â current_path = get_last_audio_for_call(call_sid)
Â Â Â Â Â Â Â Â log(f"ğŸ” Checking session memory for {call_sid} â†’ {current_path}")
Â Â Â Â Â Â Â Â print(f"ğŸ” Full session_memory[{call_sid}] = {json.dumps(session_memory.get(call_sid), indent=2)}")
Â Â Â Â Â Â Â Â if current_path and os.path.exists(current_path):
Â Â Â Â Â Â Â Â Â Â Â Â audio_path = current_path
Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â Â Â Â Â await asyncio.sleep(1)

Â Â Â Â if audio_path:
Â Â Â Â Â Â Â Â ulaw_filename = os.path.basename(audio_path)
Â Â Â Â Â Â Â Â vr.play(f"https://silent-sound-1030.fly.dev/static/audio/{ulaw_filename}")
Â Â Â Â Â Â Â Â print("ğŸ”— Final playback URL:", f"https://silent-sound-1030.fly.dev/static/audio/{ulaw_filename}")
Â Â Â Â Â Â Â Â print(f"âœ… Queued audio for playback: {ulaw_filename}")
Â Â Â Â else:
Â Â Â Â Â Â Â Â print("âŒ Audio not found after retry loop")
Â Â Â Â Â Â Â Â vr.say("Sorry, something went wrong.")
Â Â Â Â Â Â Â Â 
Â Â Â Â # âœ… Replace hangup with redirect back to self
Â Â Â Â vr.redirect("/")
Â Â Â Â print("ğŸ“ Returning TwiML to Twilio (with redirect).")
Â Â Â Â return Response(content=str(vr), media_type="application/xml")

@app.websocket("/media")
async def media_stream(ws: WebSocket):
Â Â Â Â await ws.accept()
Â Â Â Â print("â˜… Twilio WebSocket connected")

Â Â Â Â call_sid_holder = {"sid": None}
Â Â Â Â last_input_time = {"ts": time.time()}
Â Â Â Â last_transcript = {"text": "", "confidence": 0.5, "is_final": False}
Â Â Â Â finished = {"done": False}

Â Â Â Â final_transcripts = []
Â Â Â Â 
Â Â Â Â loop = asyncio.get_running_loop()
Â Â Â Â deepgram = DeepgramClient(DEEPGRAM_API_KEY)
Â Â Â Â dg_connection = None
Â Â Â Â 
Â Â Â Â try:
Â Â Â Â Â Â Â Â print("âš™ï¸ Connecting to Deepgram live transcription...")

Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â live_client = deepgram.listen.live

Â Â Â Â Â Â Â Â Â Â Â Â deepgram_options = {
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "punctuate": True,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "interim_results": True,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â "endpointing": 2000Â  # ğŸŸ¢ Wait 2000ms of silence before finalizing
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â Â Â Â Â dg_connection = await asyncio.to_thread(live_client.v, "1")
Â Â Â Â Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â Â Â Â Â print(f"â›” Failed to create Deepgram connection: {e}")
Â Â Â Â Â Â Â Â Â Â Â Â await ws.close()
Â Â Â Â Â Â Â Â Â Â Â Â return

Â Â Â Â Â Â Â Â def on_transcript(*args, **kwargs):
Â Â Â Â Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("ğŸ“¥ RAW transcript event:")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â result = kwargs.get("result") or (args[0] if args else None)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â metadata = kwargs.get("metadata")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if result is None:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("âš ï¸ No result received.")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â return

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("ğŸ“‚ Type of result:", type(result))

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if hasattr(result, "to_dict"):
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â payload = result.to_dict()
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(json.dumps(payload, indent=2))

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â sid = call_sid_holder.get("sid")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â now = time.time()
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â speech_final = payload.get("speech_final", False)

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â alt = payload["channel"]["alternatives"][0]
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â sentence = alt.get("transcript", "")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â confidence = alt.get("confidence", 0.0)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â is_final = payload["is_final"] if "is_final" in payload else False
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if is_final and sentence.strip() and confidence >= 0.6:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âœ… Final transcript received: \"{sentence}\" (confidence: {confidence})")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_input_time["ts"] = time.time()
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_transcript["text"] = sentence
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_transcript["confidence"] = confidence
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_transcript["is_final"] = True

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â final_transcripts.append(sentence)

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if speech_final:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("ğŸ§  speech_final received â€” concatenating full transcript")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â full_transcript = " ".join(final_transcripts)

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if call_sid_holder["sid"]:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â sid = call_sid_holder["sid"]
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â session_memory.setdefault(sid, {})

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â # ğŸ§  Detect overwrite â€” compare old vs new transcript
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â prev_transcript = session_memory.get(sid, {}).get("user_transcript")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â new_transcript = full_transcript.strip()

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if prev_transcript != new_transcript:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if not new_transcript:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"ğŸš¨ [OVERWRITE DETECTED - EMPTY TRANSCRIPT] SID: {sid}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f" Â  Â  ğŸ§  Previous: {repr(prev_transcript)}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f" Â  Â  âœï¸ New:Â  Â  Â  {repr(new_transcript)}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"ğŸ”¥ [OVERWRITE WARNING] SID: {sid}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f" Â  Â  ğŸ§  Previous: {repr(prev_transcript)}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f" Â  Â  âœï¸ New:Â  Â  Â  {repr(new_transcript)}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âœ… [No Overwrite] SID: {sid} â€” transcript unchanged")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â # âœ… Use full_transcript â€” it exists here
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â transcript_to_write = full_transcript
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âœï¸ [DEBUG] Writing to session_memory[{sid}]['user_transcript']: \"{transcript_to_write}\"")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â gpt_logged_at = session_memory.get(sid, {}).get("debug_gpt_input_logged_at")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if gpt_logged_at:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â delay = time.time() - gpt_logged_at
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if delay > 0:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"ğŸ”¥ [OVERWRITE WARNING] user_transcript written {delay:.2f}s AFTER GPT input was logged")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â session_memory[sid]["user_transcript"] = full_transcript
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â session_memory[sid]["ready"] = True
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â session_memory[sid]["transcript_version"] = time.time()

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â save_transcript(sid, user_transcript=full_transcript)

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â # âœ… Clear after saving
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â final_transcripts.clear()
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_transcript["text"] = ""
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_transcript["confidence"] = 0.0
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_transcript["is_final"] = False

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â elif is_final:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ Final transcript was too unclear: \"{sentence}\" (confidence: {confidence})")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â except KeyError as e:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ Missing expected key in payload: {e}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â except Exception as inner_e:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ Could not extract transcript sentence: {inner_e}")
Â Â Â Â Â Â Â Â Â Â Â Â except Exception as e:Â  # â† This closes the OUTER try
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ Error handling transcript: {e}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â dg_connection.on(LiveTranscriptionEvents.Transcript, on_transcript)

Â Â Â Â Â Â Â Â options = LiveOptions(
Â Â Â Â Â Â Â Â Â Â Â Â model="nova-3",
Â Â Â Â Â Â Â Â Â Â Â Â language="en-US",
Â Â Â Â Â Â Â Â Â Â Â Â encoding="mulaw",
Â Â Â Â Â Â Â Â Â Â Â Â sample_rate=8000,
Â Â Â Â Â Â Â Â Â Â Â Â punctuate=True,
Â Â Â Â Â Â Â Â )
Â Â Â Â Â Â Â Â print("âœï¸ LiveOptions being sent:", options.__dict__)
Â Â Â Â Â Â Â Â dg_connection.start(options)
Â Â Â Â Â Â Â Â print("âœ… Deepgram connection started")
Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â async def monitor_user_done():
Â Â Â Â Â Â Â Â Â Â Â Â while not finished["done"]:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â await asyncio.sleep(0.5)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â elapsed = time.time() - last_input_time["ts"]
Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if (
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â elapsed > 2.0 and
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_transcript["confidence"] >= 0.5 and
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_transcript.get("is_final", False)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ):
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âœ… User finished speaking (elapsed: {elapsed:.1f}s, confidence: {last_transcript['confidence']})")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â finished["done"] = True
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("â³ Waiting for POST to handle GPT + TTS...")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â for _ in range(40):Â  # up to 4 seconds
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â audio_path = session_memory.get(call_sid_holder["sid"], {}).get("audio_path")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if audio_path and os.path.exists(audio_path):
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âœ… POST-generated audio is ready: {audio_path}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â await asyncio.sleep(0.1)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â else:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("âŒ Timed out waiting for POST to generate GPT audio.")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â loop.create_task(monitor_user_done())
Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â async def sender():
Â Â Â Â Â Â Â Â Â Â Â Â while True:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â raw = await ws.receive_text()
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â except WebSocketDisconnect:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("âœ–ï¸ Twilio WebSocket disconnected")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â break
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ Unexpected error receiving message: {e}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â break

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â msg = json.loads(raw)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â except json.JSONDecodeError as e:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ JSON decode error: {e}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â continue

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â event = msg.get("event")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â if event == "start":
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("â–¶ï¸ Stream started (StreamSid:", msg["start"].get("streamSid"), ")")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â # Debug print to inspect what Twilio actually sent
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("ğŸ§¾ Twilio start event data:", json.dumps(msg["start"], indent=2))

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â # Try all possible keys Twilio might send
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â sid = (
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â msg["start"].get("callSid") or
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â msg["start"].get("CallSid") or
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â msg["start"].get("callerSid") or
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â msg["start"].get("CallerSid")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â )

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â call_sid_holder["sid"] = sid
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"ğŸ“ [WebSocket] call_sid_holder['sid']: {call_sid_holder['sid']}")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â elif event == "media":
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â payload = base64.b64decode(msg["media"]["payload"])
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â dg_connection.send(payload)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â last_input_time["ts"] = time.time()
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ Error sending to Deepgram: {e}")

Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â elif event == "stop":
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print("â¹ Stream stopped by Twilio")
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â break

Â Â Â Â Â Â Â Â await sender()

Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â print(f"â›” Deepgram error: {e}")

Â Â Â Â finally:
Â Â Â Â Â Â Â Â if dg_connection:
Â Â Â Â Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â dg_connection.finish()
Â Â Â Â Â Â Â Â Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ Error closing Deepgram connection: {e}")
Â Â Â Â Â Â Â Â try:
Â Â Â Â Â Â Â Â Â Â Â Â await ws.close()
Â Â Â Â Â Â Â Â except Exception as e:
Â Â Â Â Â Â Â Â Â Â Â Â print(f"âš ï¸ Error closing WebSocket: {e}")
Â Â Â Â Â Â Â Â print("âœ… Connection closed")
Â Â Â Â Â Â Â 